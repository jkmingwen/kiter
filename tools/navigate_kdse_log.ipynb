{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078e0214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aef2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad6ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_step_sizes (df) :\n",
    "    feedback_quantities = df['feedback quantities'].str.split(',', expand=True).astype(int)\n",
    "    step_sizes = []\n",
    "    for col in feedback_quantities :\n",
    "        tmp = sorted(feedback_quantities[col].unique())\n",
    "        if len(tmp) < 2 :\n",
    "            step_sizes.append(0)\n",
    "        else :\n",
    "            step_sizes.append(tmp[1] - tmp[0])\n",
    "            \n",
    "    return step_sizes\n",
    "\n",
    "\n",
    "def split_list_in_dataframe(df, colname) :\n",
    "    new_df = df.drop(columns=[colname]).copy()\n",
    "    new_cols = df[colname].str.split(',', expand=True).astype(int)\n",
    "    new_col_names = [f\"{colname}_{x}\" for x in range(len(new_cols.columns))]\n",
    "    new_df[new_col_names] = new_cols.copy()\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a826ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_next(step_sizes) :\n",
    "    def inner_compute_next(row) :\n",
    "        criticals = list(map(int, [x for x in row[\"critical feedback\"].split(',') if x != \"\"]))\n",
    "        originals = list(map(int, [x for x in row[\"feedback quantities\"].split(',') if x != \"\"]))\n",
    "        res = []\n",
    "        for critical_buffer_idx in criticals :\n",
    "            critical_buffer_idx = critical_buffer_idx - 1\n",
    "            next_configuration = originals.copy()\n",
    "            if step_sizes[critical_buffer_idx] > 0 :\n",
    "                next_configuration[critical_buffer_idx] = next_configuration[critical_buffer_idx] + step_sizes[critical_buffer_idx]\n",
    "                res.append(\",\".join(map(str, next_configuration)))\n",
    "        return res\n",
    "    return inner_compute_next\n",
    "\n",
    "def turn_config_to_index(df) :\n",
    "    df_by_fq = df.reset_index(names=\"index\").set_index(\"feedback quantities\")\n",
    "\n",
    "    def inner_turn_config_to_index(row) :\n",
    "        next_configs = row[\"next configurations\"]\n",
    "        next_configs_indexes = []\n",
    "        for config in next_configs :\n",
    "            try :\n",
    "                next_configs_indexes.append(df_by_fq.loc[config][\"index\"])\n",
    "            except KeyError :\n",
    "                pass\n",
    "        # list(map(lambda x : df_by_fq.loc[x][\"index\"], ))\n",
    "        return next_configs_indexes\n",
    "    return inner_turn_config_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97fd03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_file (filename) :\n",
    "    \n",
    "    # load one particular file\n",
    "    import numpy as np \n",
    "\n",
    "    df = pd.read_csv(filename, dtype = {\"throughput\" : np.float64,\n",
    "                                                         \"storage distribution size\": np.int64,\n",
    "                                                         \"feedback quantities\" : str,\n",
    "                                                         \"critical feedback\" : str,\n",
    "                                                        })\n",
    "    df = df[[\"throughput\",\"storage distribution size\",\"feedback quantities\",\"critical feedback\"]]\n",
    "    df[\"critical feedback\"] = df[\"critical feedback\"].fillna(\"\")\n",
    "\n",
    "    # Given the step sizes, and critical feedbackm we can compute the next configurations, \n",
    "    # handy to generate the graph properly.\n",
    "    step_sizes = calculate_step_sizes(df)\n",
    "    df[\"next configurations\"] = df.apply(compute_next(step_sizes),axis=1)\n",
    "    df[\"next configurations\"] = df.apply(turn_config_to_index(df),axis=1)\n",
    "\n",
    "    tmp_df = df.reset_index(names=\"index\")\n",
    "    df[\"past configurations\"] = tmp_df.apply(lambda x :  [idx for idx,y in enumerate(tmp_df[\"next configurations\"]) if x[\"index\"] in y] , axis = 1)\n",
    "\n",
    "\n",
    "    # Compute X and Y position for the visualization.\n",
    "    df['Y'] = 50*(df['storage distribution size'].diff(1).shift(0) > 0).cumsum()\n",
    "    df['X'] = 400*df.groupby('storage distribution size').cumcount()\n",
    "\n",
    "    df[\"interesting\"] = df.apply(lambda x : x[\"throughput\"] > df.loc[[y for y in x[\"past configurations\"]]][\"throughput\"].max() , axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59611b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvis\n",
    "#97c2fc80\n",
    "UNUSED_COLOR='#97c2fc80'\n",
    "USED_COLOR='#97c2fc'\n",
    "INTERESTING_COLOR='#ff5733'\n",
    "\n",
    "def generate_config_graph(df):\n",
    "    \n",
    "    step_sizes = calculate_step_sizes(df)\n",
    "    print(step_sizes)\n",
    "    \n",
    "    feedback_quantities = df['feedback quantities'].str.split(',', expand=True).astype(int)\n",
    "    \n",
    "    col_of_interest = [x for x in feedback_quantities.columns if step_sizes[x] > 0 ]\n",
    "    feedback_quantities = feedback_quantities[col_of_interest]\n",
    "    step_sizes = [x for x in step_sizes if x > 0]\n",
    "    \n",
    "    names_feedback_quantities = feedback_quantities[col_of_interest].apply(lambda x : \",\".join(x.astype(str)),axis=1)\n",
    "    \n",
    "    #  \n",
    "    # Create a directed graph\n",
    "    net = Network(notebook=True)\n",
    "    # Add nodes and edges to the graph\n",
    "    for i, row1 in feedback_quantities.iterrows():\n",
    "        \n",
    "        # decide of the color\n",
    "        interesting = df.iloc[i][\"interesting\"] \n",
    "        color = USED_COLOR\n",
    "        if interesting :\n",
    "            color = INTERESTING_COLOR\n",
    "        \n",
    "        net.add_node(i,physics=False, \n",
    "                     x=int(df.iloc[i][\"X\"]), \n",
    "                     y=int(df.iloc[i][\"Y\"]), \n",
    "                     label=str(df.iloc[i][\"storage distribution size\"]) + \"(\" + str(df.iloc[i][\"throughput\"])+ \")\", \n",
    "                     title=f\"{names_feedback_quantities.iloc[i]}\\n{df.iloc[i]}\", \n",
    "                     shape='box', \n",
    "                     borderWidth=3 if i == 0 else 0,\n",
    "                     color=color,\n",
    "                    )  # Set size to 20 for the first node, 10 for others\n",
    "     \n",
    "    for i, row1 in feedback_quantities.iterrows():\n",
    "        for j in df.iloc[i][\"next configurations\"]:\n",
    "            net.add_edge(i, int(j), width = 2)\n",
    "                \n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cba09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "kdse_logs = {}\n",
    "\n",
    "#Load all the files\n",
    "filenames = [x for x in glob.glob('../kdse2023_log/*__athroughputbufferingDSE__prealtime_1__pmode_*.txt')]\n",
    "\n",
    "for f in filenames :\n",
    "    matching = re.match('.*/(.*)__athroughputbufferingDSE__prealtime_1__pmode_(.*).txt', f)\n",
    "    if matching :\n",
    "        name = matching.group(1)\n",
    "        method = matching.group(2)\n",
    "        if not name in kdse_logs:\n",
    "            kdse_logs[name] = {}\n",
    "        kdse_logs[name][method] = f        \n",
    "kdse_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490cdde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_one_file(kdse_logs[\"fig8\"][\"KDSE\"])\n",
    "net = generate_config_graph(df)\n",
    "net.show(\"interactive_network.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df619572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_one_file(kdse_logs[\"fig8\"][\"K2DSE\"])\n",
    "net = generate_config_graph(df)\n",
    "net.show(\"interactive_network.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f23379",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_one_file(kdse_logs[\"fig8\"][\"K2DSEA\"])\n",
    "net = generate_config_graph(df)\n",
    "net.show(\"interactive_network.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9dc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
